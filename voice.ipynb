{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "import soundfile as sf\n",
    "\n",
    "class CustomVoiceNarrator:\n",
    "    def __init__(self, voice_samples_dir):\n",
    "        \"\"\"Initialize the custom voice narrator with a directory of voice samples\"\"\"\n",
    "        self.voice_samples_dir = Path(voice_samples_dir)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Initialize models\n",
    "        self.processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "        self.model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\").to(self.device)\n",
    "        self.vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\").to(self.device)\n",
    "        \n",
    "        # Process voice samples to create speaker embedding\n",
    "        self.speaker_embedding = self._create_speaker_embedding()\n",
    "    \n",
    "    def _create_speaker_embedding(self):\n",
    "        \"\"\"Create a speaker embedding from voice samples\"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        for audio_file in self.voice_samples_dir.glob(\"*.wav\"):\n",
    "            # Load and preprocess audio\n",
    "            speech, sr = librosa.load(str(audio_file), sr=16000)\n",
    "            speech = librosa.effects.trim(speech)[0]\n",
    "            \n",
    "            # Convert to tensor\n",
    "            inputs = self.processor(\n",
    "                audio=speech,\n",
    "                sampling_rate=sr,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Generate speaker embedding\n",
    "            with torch.no_grad():\n",
    "                encoder_output = self.model.encode_speech(\n",
    "                    inputs[\"input_values\"].to(self.device),\n",
    "                    return_dict=True\n",
    "                )\n",
    "                embedding = encoder_output.last_hidden_state.mean(dim=1)\n",
    "            embeddings.append(embedding)\n",
    "        \n",
    "        # Average all embeddings\n",
    "        return torch.mean(torch.stack(embeddings), dim=0)\n",
    "    \n",
    "    def narrate(self, text, output_path):\n",
    "        \"\"\"Generate speech from text using the custom voice\"\"\"\n",
    "        # Preprocess text\n",
    "        inputs = self.processor(text=text, return_tensors=\"pt\")\n",
    "        \n",
    "        # Generate speech\n",
    "        speech = self.model.generate_speech(\n",
    "            inputs[\"input_ids\"].to(self.device),\n",
    "            self.speaker_embedding.to(self.device),\n",
    "            vocoder=self.vocoder\n",
    "        )\n",
    "        \n",
    "        # Save the generated speech\n",
    "        sf.write(output_path, speech.cpu().numpy(), samplerate=16000)\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize narrator with directory containing voice samples\n",
    "    narrator = CustomVoiceNarrator(\"voice_samples\")\n",
    "    \n",
    "    # Generate speech with custom voice\n",
    "    text = \"Hello, this is a test of the custom voice narrator.\"\n",
    "    output_path = \"generated_speech.wav\"\n",
    "    narrator.narrate(text, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
