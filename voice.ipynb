{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcant\\OneDrive\\Documents\\GitHub\\Custom-Voice-Narrator\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\mcant\\OneDrive\\Documents\\GitHub\\Custom-Voice-Narrator\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mcant\\.cache\\huggingface\\hub\\models--microsoft--speecht5_tts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\mcant\\OneDrive\\Documents\\GitHub\\Custom-Voice-Narrator\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mcant\\.cache\\huggingface\\hub\\models--microsoft--speecht5_hifigan. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SpeechT5ForTextToSpeech' object has no attribute 'get_speaker_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Initialize narrator with directory containing voice samples\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     narrator \u001b[38;5;241m=\u001b[39m \u001b[43mCustomVoiceNarrator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoice_samples\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Generate speech with custom voice\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, this is a test of the custom voice narrator.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m, in \u001b[0;36mCustomVoiceNarrator.__init__\u001b[1;34m(self, voice_samples_dir)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocoder \u001b[38;5;241m=\u001b[39m SpeechT5HifiGan\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/speecht5_hifigan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Process voice samples to create speaker embedding\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeaker_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_speaker_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m, in \u001b[0;36mCustomVoiceNarrator._create_speaker_embedding\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Generate speaker embedding\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 40\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_speaker_embeddings\u001b[49m(\n\u001b[0;32m     41\u001b[0m             inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     42\u001b[0m         )\n\u001b[0;32m     43\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Average all embeddings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mcant\\OneDrive\\Documents\\GitHub\\Custom-Voice-Narrator\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SpeechT5ForTextToSpeech' object has no attribute 'get_speaker_embeddings'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "import soundfile as sf\n",
    "\n",
    "class CustomVoiceNarrator:\n",
    "    def __init__(self, voice_samples_dir):\n",
    "        \"\"\"Initialize the custom voice narrator with a directory of voice samples\"\"\"\n",
    "        self.voice_samples_dir = Path(voice_samples_dir)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Initialize models\n",
    "        self.processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "        self.model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\").to(self.device)\n",
    "        self.vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\").to(self.device)\n",
    "        \n",
    "        # Process voice samples to create speaker embedding\n",
    "        self.speaker_embedding = self._create_speaker_embedding()\n",
    "    \n",
    "    def _create_speaker_embedding(self):\n",
    "        \"\"\"Create a speaker embedding from voice samples\"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        for audio_file in self.voice_samples_dir.glob(\"*.wav\"):\n",
    "            # Load and preprocess audio\n",
    "            speech, sr = librosa.load(str(audio_file), sr=16000)\n",
    "            speech = librosa.effects.trim(speech)[0]\n",
    "            \n",
    "            # Convert to tensor\n",
    "            inputs = self.processor(\n",
    "                audio=speech,\n",
    "                sampling_rate=sr,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Generate speaker embedding\n",
    "            with torch.no_grad():\n",
    "                embedding = self.model.get_encoder_hidden_states(\n",
    "                    inputs[\"input_values\"].to(self.device)\n",
    "                ).last_hidden_state.mean(dim=1)\n",
    "            embeddings.append(embedding)\n",
    "        \n",
    "        # Average all embeddings\n",
    "        return torch.mean(torch.stack(embeddings), dim=0)\n",
    "    \n",
    "    def narrate(self, text, output_path):\n",
    "        \"\"\"Generate speech from text using the custom voice\"\"\"\n",
    "        # Preprocess text\n",
    "        inputs = self.processor(text=text, return_tensors=\"pt\")\n",
    "        \n",
    "        # Generate speech\n",
    "        speech = self.model.generate_speech(\n",
    "            inputs[\"input_ids\"].to(self.device),\n",
    "            self.speaker_embedding.to(self.device),\n",
    "            vocoder=self.vocoder\n",
    "        )\n",
    "        \n",
    "        # Save the generated speech\n",
    "        sf.write(output_path, speech.cpu().numpy(), samplerate=16000)\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize narrator with directory containing voice samples\n",
    "    narrator = CustomVoiceNarrator(\"voice_samples\")\n",
    "    \n",
    "    # Generate speech with custom voice\n",
    "    text = \"Hello, this is a test of the custom voice narrator.\"\n",
    "    output_path = \"generated_speech.wav\"\n",
    "    narrator.narrate(text, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
